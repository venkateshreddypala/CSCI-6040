{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "token.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wd1HfeiazJaM",
        "colab_type": "text"
      },
      "source": [
        "# Word Tokenization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwVlGbco0u0Y",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "> **Tokenize text into words.**\n",
        "\n",
        "Tokenization is a way to split text into tokens. These tokens could be paragraphs, sentences, or individual words.\n",
        "\n",
        "\n",
        "There are many libraries such as NLTK, spaCy, Genisim which have built-in functions to perform several tasks.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        " > Requires more string manipulation techniques than str.split()\n",
        " \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08FlT5awIQKL",
        "colab_type": "code",
        "outputId": "25c914c7-314f-49c3-e74e-43df8b7202c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# built-in functions in Python \n",
        "# This does a dirty- splut, we can see'.' included\n",
        "\n",
        "senten = \"\"\"This is introduction to NLP & NLU.\"\"\"\n",
        "\n",
        "senten.split()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['This', 'is', 'introduction', 'to', 'NLP', '&', 'NLU.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQwJ4UDOI7HD",
        "colab_type": "code",
        "outputId": "60020174-be4c-468f-9359-5a3794058642",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "str.split(senten)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['This', 'is', 'introduction', 'to', 'NLP', '&', 'NLU.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ch2E2g6QpvOZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "878f696a-208a-42ff-ae9b-15ecf7e15edc"
      },
      "source": [
        "# tokenizing using NLTK\n",
        "\n",
        "import nltk.data\n",
        "nltk.download('punkt')\n",
        "nltk.word_tokenize(senten)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['This', 'is', 'introduction', 'to', 'NLP', '&', 'NLU', '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "poK0tvQBrWMa",
        "colab_type": "text"
      },
      "source": [
        "*The major difference between built-in function and NLTK/spaCy is split function ignores the '.' where as in NLTK/spaCy it is seperated.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWoBPJcyvszH",
        "colab_type": "text"
      },
      "source": [
        "**One-hot Vectors**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGF5o26juoJB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 850
        },
        "outputId": "3354e3fe-48f5-4799-9f92-1d888745bbe4"
      },
      "source": [
        "# importing numpy\n",
        "import numpy as np\n",
        "# creating a vocab to keep track of all unique words\n",
        "token_sequence = str.split(senten)\n",
        "# Sorted lexographically (lexically) so numbers come before letters,\n",
        "# and capital letters come before lowercase letters\n",
        "vocab = sorted(set(token_sequence))\n",
        "', '.join(vocab)\n",
        "num_tokens = len(token_sequence)\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "# For each word in the sentence, mark the column for that \n",
        "# word in your vocabulary with a 1\n",
        "onehot_vectors = np.zeros((num_tokens, vocab_size), int) \n",
        "for i, word in enumerate(token_sequence):\n",
        "  onehot_vectors[i, vocab.index(word)] = 1\n",
        "  ' '.join(vocab)\n",
        "  print(onehot_vectors)\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 0 0 1 0 0 0]\n",
            " [0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0]]\n",
            "[[0 0 0 1 0 0 0]\n",
            " [0 0 0 0 0 1 0]\n",
            " [0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0]]\n",
            "[[0 0 0 1 0 0 0]\n",
            " [0 0 0 0 0 1 0]\n",
            " [0 0 0 0 1 0 0]\n",
            " [0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0]]\n",
            "[[0 0 0 1 0 0 0]\n",
            " [0 0 0 0 0 1 0]\n",
            " [0 0 0 0 1 0 0]\n",
            " [0 0 0 0 0 0 1]\n",
            " [0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0]]\n",
            "[[0 0 0 1 0 0 0]\n",
            " [0 0 0 0 0 1 0]\n",
            " [0 0 0 0 1 0 0]\n",
            " [0 0 0 0 0 0 1]\n",
            " [0 1 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0]]\n",
            "[[0 0 0 1 0 0 0]\n",
            " [0 0 0 0 0 1 0]\n",
            " [0 0 0 0 1 0 0]\n",
            " [0 0 0 0 0 0 1]\n",
            " [0 1 0 0 0 0 0]\n",
            " [1 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0]]\n",
            "[[0 0 0 1 0 0 0]\n",
            " [0 0 0 0 0 1 0]\n",
            " [0 0 0 0 1 0 0]\n",
            " [0 0 0 0 0 0 1]\n",
            " [0 1 0 0 0 0 0]\n",
            " [1 0 0 0 0 0 0]\n",
            " [0 0 1 0 0 0 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wv5LSbYGwf5c",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "*   As we can see it is a bit hard to read the zeros in the above representation and pandas can make the representation a bit easy to read.\n",
        "\n",
        "*  DataFrames  in Pandas will make this more informative.\n",
        "\n",
        "* It wraps a 1D array with some helper functionality in an object called a Series. \n",
        "\n",
        "* Pandas is useful with tables of numbers like lists of lists, 2D numpy arrays, 2D numpy matrices, arrays of arrays, dictionaries of dictionaries, and so on.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSGmfTEqxoBT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "outputId": "5488910a-3e6f-4714-cbf1-d565c65ea206"
      },
      "source": [
        "# One-hot vector sequence\n",
        "import pandas as pd \n",
        "pd.DataFrame(onehot_vectors, columns=vocab)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>&amp;</th>\n",
              "      <th>NLP</th>\n",
              "      <th>NLU.</th>\n",
              "      <th>This</th>\n",
              "      <th>introduction</th>\n",
              "      <th>is</th>\n",
              "      <th>to</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   &  NLP  NLU.  This  introduction  is  to\n",
              "0  0    0     0     1             0   0   0\n",
              "1  0    0     0     0             0   1   0\n",
              "2  0    0     0     0             1   0   0\n",
              "3  0    0     0     0             0   0   1\n",
              "4  0    1     0     0             0   0   0\n",
              "5  1    0     0     0             0   0   0\n",
              "6  0    0     1     0             0   0   0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYNE9jpUx6k6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "outputId": "d54c518c-bb5b-4b74-e7f4-c7d054a24a43"
      },
      "source": [
        "# remove the zeros from above matrix\n",
        "\n",
        "df = pd.DataFrame(onehot_vectors, columns=vocab)\n",
        "df[df == 0] = ''\n",
        "df"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>&amp;</th>\n",
              "      <th>NLP</th>\n",
              "      <th>NLU.</th>\n",
              "      <th>This</th>\n",
              "      <th>introduction</th>\n",
              "      <th>is</th>\n",
              "      <th>to</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   & NLP NLU. This introduction is to\n",
              "0                1                   \n",
              "1                                1   \n",
              "2                             1      \n",
              "3                                   1\n",
              "4      1                             \n",
              "5  1                                 \n",
              "6           1                        "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58da3a4Rk10j",
        "colab_type": "text"
      },
      "source": [
        "# Normalizing the Text\n",
        "\n",
        "Lower casing is one of the pre-processing steps in textual data.\n",
        "\n",
        "We want both USA and usa to be the same while analysis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hY-csjTGXI-2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "ba30f5ca-2140-4f14-b42c-c5f3c51b5954"
      },
      "source": [
        "# Converting a list to a dataframe\n",
        "\n",
        "text=['This is introduction to NLP & NLU', 'It is likely to be useful to students',\n",
        "     'Deep learning is the new electrcity' , 'python is the best language!' , \n",
        "     'I like this note-book', 'I want to learn more from these note-books']\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "df = pd.DataFrame({'tweet':text})\n",
        "print(df)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                        tweet\n",
            "0           This is introduction to NLP & NLU\n",
            "1       It is likely to be useful to students\n",
            "2         Deep learning is the new electrcity\n",
            "3                python is the best language!\n",
            "4                       I like this note-book\n",
            "5  I want to learn more from these note-books\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gN9OLMKOXR91",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "3d311060-1737-4476-e131-c3b1f4326036"
      },
      "source": [
        "# Lowercasing to this dataframe\n",
        "\n",
        "df['tweet'] = df['tweet'].apply(lambda x: \" \".join(x.lower()\n",
        "for x in x.split()))\n",
        "df['tweet']"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0             this is introduction to nlp & nlu\n",
              "1         it is likely to be useful to students\n",
              "2           deep learning is the new electrcity\n",
              "3                  python is the best language!\n",
              "4                         i like this note-book\n",
              "5    i want to learn more from these note-books\n",
              "Name: tweet, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e71VMFL6ZcDv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
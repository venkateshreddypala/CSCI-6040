{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "token.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wd1HfeiazJaM",
        "colab_type": "text"
      },
      "source": [
        "# Word Tokenization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwVlGbco0u0Y",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "> **Tokenize text into words.**\n",
        "\n",
        "Tokenization is a way to split text into tokens. These tokens could be paragraphs, sentences, or individual words.\n",
        "\n",
        "\n",
        "There are many libraries such as NLTK, spaCy, Genisim which have built-in functions to perform several tasks.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        " > Requires more string manipulation techniques than str.split()\n",
        " \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08FlT5awIQKL",
        "colab_type": "code",
        "outputId": "ec8c4c43-e435-4a1d-b204-d994da907c1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "# built-in functions in Python \n",
        "# This does a dirty- splut, we can see'.' included\n",
        "\n",
        "senten = \"\"\"Natural Language Processing with Deep Leanring is advancement \n",
        "in this\n",
        "feild but there are still some topic which are relevant for \n",
        "NLP.\"\"\"\n",
        "\n",
        "senten.split()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Natural',\n",
              " 'Language',\n",
              " 'Processing',\n",
              " 'with',\n",
              " 'Deep',\n",
              " 'Leanring',\n",
              " 'is',\n",
              " 'advancement',\n",
              " 'in',\n",
              " 'this',\n",
              " 'feild',\n",
              " 'but',\n",
              " 'there',\n",
              " 'are',\n",
              " 'still',\n",
              " 'some',\n",
              " 'topic',\n",
              " 'which',\n",
              " 'are',\n",
              " 'relevant',\n",
              " 'for',\n",
              " 'NLP.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQwJ4UDOI7HD",
        "colab_type": "code",
        "outputId": "2e3388f4-59dd-4f87-c65b-2bdda1a271e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "str.split(senten)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Natural',\n",
              " 'Language',\n",
              " 'Processing',\n",
              " 'with',\n",
              " 'Deep',\n",
              " 'Leanring',\n",
              " 'is',\n",
              " 'advancement',\n",
              " 'in',\n",
              " 'this',\n",
              " 'feild',\n",
              " 'but',\n",
              " 'there',\n",
              " 'are',\n",
              " 'still',\n",
              " 'some',\n",
              " 'topic',\n",
              " 'which',\n",
              " 'are',\n",
              " 'relevant',\n",
              " 'for',\n",
              " 'NLP.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ch2E2g6QpvOZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "f8178ffa-2189-45b0-85a4-357d7303a9c8"
      },
      "source": [
        "# tokenizing using NLTK\n",
        "\n",
        "import nltk.data\n",
        "nltk.download('punkt')\n",
        "nltk.word_tokenize(senten)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Natural',\n",
              " 'Language',\n",
              " 'Processing',\n",
              " 'with',\n",
              " 'Deep',\n",
              " 'Leanring',\n",
              " 'is',\n",
              " 'advancement',\n",
              " 'in',\n",
              " 'this',\n",
              " 'feild',\n",
              " 'but',\n",
              " 'there',\n",
              " 'are',\n",
              " 'still',\n",
              " 'some',\n",
              " 'topic',\n",
              " 'which',\n",
              " 'are',\n",
              " 'relevant',\n",
              " 'for',\n",
              " 'NLP',\n",
              " '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "poK0tvQBrWMa",
        "colab_type": "text"
      },
      "source": [
        "**The major difference between built-in function and NLTK/spaCy is split function ignores the '.' where as in NLTK/spaCy it is seperated.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58da3a4Rk10j",
        "colab_type": "text"
      },
      "source": [
        "# Lower Casing\n",
        "\n",
        "It is one of the pre-processing steps in textual data.\n",
        "\n",
        "We want both USA and usa to be the same while analysis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hY-csjTGXI-2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "0c059f95-cdae-4cfe-8855-579601a66f2c"
      },
      "source": [
        "# Converting a list to a dataframe\n",
        "\n",
        "text=['This is introduction to NLP & NLU', 'It is likely to be useful to students',\n",
        "     'Deep learning is the new electrcity' , 'python is the best language!' , \n",
        "     'I like this note-book', 'I want to learn more from these note-books']\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "df = pd.DataFrame({'tweet':text})\n",
        "print(df)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                        tweet\n",
            "0           This is introduction to NLP & NLU\n",
            "1       It is likely to be useful to students\n",
            "2         Deep learning is the new electrcity\n",
            "3                python is the best language!\n",
            "4                       I like this note-book\n",
            "5  I want to learn more from these note-books\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gN9OLMKOXR91",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "865788e3-b08a-47f9-a9dc-dada9f3b27c4"
      },
      "source": [
        "# Lowercasing to this dataframe\n",
        "\n",
        "df['tweet'] = df['tweet'].apply(lambda x: \" \".join(x.lower()\n",
        "for x in x.split()))\n",
        "df['tweet']"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0             this is introduction to nlp & nlu\n",
              "1         it is likely to be useful to students\n",
              "2           deep learning is the new electrcity\n",
              "3                  python is the best language!\n",
              "4                         i like this note-book\n",
              "5    i want to learn more from these note-books\n",
              "Name: tweet, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e71VMFL6ZcDv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}